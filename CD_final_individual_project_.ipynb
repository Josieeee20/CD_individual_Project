{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92dca078",
   "metadata": {},
   "source": [
    "# The intruduction of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e2a47",
   "metadata": {},
   "source": [
    "This project primarily investigates the (https://www.fmprc.gov.cn/mfa_eng/) Chinese Ministry of Foreign Affairs' public statements in December, examining the responses from China to relevant affairs of which countries or regions during the month, along with the expressed opinions and attitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314a9df",
   "metadata": {},
   "source": [
    "#  Webscrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a9ea1",
   "metadata": {},
   "source": [
    "## The introduction of the libraries\n",
    "- requests:\n",
    "Used for making HTTP requests to fetch data from web servers.\n",
    "BeautifulSoup:\n",
    "A library for parsing HTML and XML documents, commonly used in web scraping.\n",
    "- csv:\n",
    "A built-in module for reading and writing CSV files, simplifying handling tabular data.\n",
    "urllib.parse:\n",
    "Provides functions for parsing and manipulating URLs.\n",
    "- re:\n",
    "The regular expressions module for powerful string pattern matching and manipulation.\n",
    "- os:\n",
    "Interacts with the operating system, often used for file and directory manipulation.\n",
    "unicodedata:\n",
    "Provides access to the Unicode Character Database, useful for working with Unicode characters and strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96e69170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import urllib.parse\n",
    "import re\n",
    "import os\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af06383",
   "metadata": {},
   "source": [
    "Firstly we collect the data from the website(https://www.fmprc.gov.cn/eng/xwfw_665399/s2510_665401/2511_665403/)and save it in a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84a319f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_save_news(url, output_file):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    news_list = soup.find(\"div\", class_=\"newsLst_mod\").find_all(\"li\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    base_url = \"https://www.fmprc.gov.cn/eng/xwfw_665399/s2510_665401/2511_665403/\"\n",
    "\n",
    "    for news_item in news_list:\n",
    "        title = news_item.find(\"a\").text.strip()\n",
    "        news_url_relative = news_item.find(\"a\")['href']\n",
    "\n",
    "        # Splice the relative path and the base URL to get the complete news link\n",
    "        news_url = urllib.parse.urljoin(base_url, news_url_relative)\n",
    "\n",
    "        # Get the content of the news content page\n",
    "        content_response = requests.get(news_url)\n",
    "        content_soup = BeautifulSoup(content_response.text, \"html.parser\")\n",
    "\n",
    "        # Get news content\n",
    "        content_paragraphs = content_soup.find(\"div\", class_=\"content\").find_all(\"p\")  \n",
    "        content_text = \" \".join([p.text.strip() for p in content_paragraphs])\n",
    "\n",
    "        # Add title and content to data list\n",
    "        data.append({\"Title\": title, \"Content\": content_text})\n",
    "\n",
    "    # Write data to CSV file\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = [\"Title\", \"Content\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Replace with actual URL and output filename\n",
    "url_to_scrape = \"https://www.fmprc.gov.cn/eng/xwfw_665399/s2510_665401/2511_665403/index.html\"\n",
    "output_csv_file = \"news_data.csv\"\n",
    "\n",
    "scrape_and_save_news(url_to_scrape, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f50d20",
   "metadata": {},
   "source": [
    "Due to the large amount of saved data, we only selected content with the title \"December.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a726d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_save_december_news(url, output_file):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    news_list = soup.find(\"div\", class_=\"newsLst_mod\").find_all(\"li\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    base_url = \"https://www.fmprc.gov.cn/eng/xwfw_665399/s2510_665401/2511_665403/\"\n",
    "\n",
    "    for news_item in news_list:\n",
    "        title = news_item.find(\"a\").text.strip()\n",
    "        \n",
    "        if \"December\" in title:\n",
    "            news_url_relative = news_item.find(\"a\")['href']\n",
    "            \n",
    "            # Splice the relative path and the base URL to get the complete news link\n",
    "            news_url = urllib.parse.urljoin(base_url, news_url_relative)\n",
    "\n",
    "            # Get the content of the news content page\n",
    "            content_response = requests.get(news_url)\n",
    "            content_soup = BeautifulSoup(content_response.text, \"html.parser\")\n",
    "            content_paragraphs = content_soup.find(\"div\", class_=\"content\").find_all(\"p\") \n",
    "            content_text = \" \".join([p.text.strip() for p in content_paragraphs])\n",
    "\n",
    "            # Add title and content to data list\n",
    "            data.append({\"Title\": title, \"Content\": content_text})\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = [\"Title\", \"Content\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "url_to_scrape = \"https://www.fmprc.gov.cn/eng/xwfw_665399/s2510_665401/2511_665403/index.html\"\n",
    "output_csv_file = \"december_news_data.csv\"\n",
    "\n",
    "scrape_and_save_december_news(url_to_scrape, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec802c64",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70a303",
   "metadata": {},
   "source": [
    "Clean up the text, retaining only normal punctuation and textual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9c78ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z.,!? ]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def clean_and_save_to_csv(input_csv_file, output_csv_file):\n",
    "    data = []\n",
    "\n",
    "    with open(input_csv_file, 'r', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            title = row[\"Title\"]\n",
    "            content = row[\"Content\"]\n",
    "\n",
    "            cleaned_content_text = clean_text(content)\n",
    "\n",
    "            data.append({\"Title\": title, \"Content\": cleaned_content_text})\n",
    "\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = [\"Title\", \"Content\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "input_csv_file = \"december_news_data.csv\"\n",
    "output_csv_file = \"cleaned_data.csv\"\n",
    "\n",
    "clean_and_save_to_csv(input_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823e847",
   "metadata": {},
   "source": [
    "Split the text content into multiple TXT files and rename them in the format of \"txt_01.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "173eaaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_to_txt(title, content, output_folder, file_count):\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    filename = f\"txt_{file_count:02d}.txt\"\n",
    "\n",
    "    with open(os.path.join(output_folder, filename), 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(f\"Title: {title}\\n\\n\")\n",
    "        txt_file.write(f\"Content:\\n{content}\")\n",
    "\n",
    "def split_csv_to_txt(input_csv_file, output_folder):\n",
    "    with open(input_csv_file, 'r', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for idx, row in enumerate(reader, start=1):\n",
    "            title = row[\"Title\"]\n",
    "            content = row[\"Content\"]\n",
    "\n",
    "            cleaned_content_text = clean_text(content)\n",
    "\n",
    "            save_to_txt(title, cleaned_content_text, output_folder, idx)\n",
    "\n",
    "input_csv_file = \"cleaned_data.csv\"\n",
    "output_folder = \"output_txt_files\"\n",
    "\n",
    "split_csv_to_txt(input_csv_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52264088",
   "metadata": {},
   "source": [
    "# Install Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739c55d",
   "metadata": {},
   "source": [
    "- Install and Import Libraries: The code installs spaCy and Plotly libraries using %pip install and imports necessary packages.\n",
    "\n",
    "- Install English Language Model: It downloads and installs the English language model for spaCy using !python -m spacy download en_core_web_sm.\n",
    "\n",
    "- Load spaCy Model: It loads the English language model into spaCy using nlp = spacy.load(\"en_core_web_sm\").\n",
    "\n",
    "- Import spaCy Visualizer: The code imports the spaCy visualizer displacy for later use in visualizing text annotations.\n",
    "\n",
    "- Import Other Libraries: It imports additional libraries such as os for file handling, pandas for data manipulation, and Plotly for graphing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e8f6149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spaCy in /Users/josiechen/anaconda3/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spaCy) (1.24.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spaCy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spaCy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spaCy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spaCy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from jinja2->spaCy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in /Users/josiechen/anaconda3/lib/python3.11/site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from plotly) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nbformat in /Users/josiechen/anaconda3/lib/python3.11/site-packages (5.9.2)\n",
      "Requirement already satisfied: fastjsonschema in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from nbformat) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from nbformat) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from nbformat) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from nbformat) (5.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from jupyter-core->nbformat) (2.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install and import spacy and plotly.\n",
    "%pip install spaCy\n",
    "%pip install plotly\n",
    "%pip install nbformat --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fdb3d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/josiechen/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# Install English language model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Import os to upload documents and metadata\n",
    "import os\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load spaCy visualizer\n",
    "from spacy import displacy\n",
    "\n",
    "# Import pandas DataFrame packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Import graphing package\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed1c1ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists for file names and contents\n",
    "texts = []\n",
    "file_names = []\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for _file_name in os.listdir('cleaned_txt_files'):\n",
    "# Look for only text files\n",
    "    if _file_name.endswith('.txt'):\n",
    "    # Append contents of each text file to text list\n",
    "        texts.append(open('cleaned_txt_files' + '/' + _file_name, 'r', encoding='utf-8').read())\n",
    "        # Append name of each file to file name list\n",
    "        file_names.append(_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "756bed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary object associating each file name with its text\n",
    "d = {'Filename':file_names,'Text':texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0bf62adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dictionary into a dataframe\n",
    "News_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb8176d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txt_11.txt</td>\n",
       "      <td>We noted that General Secretary and President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txt_05.txt</td>\n",
       "      <td>CCTV This year marks the tenth anniversary of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>txt_04.txt</td>\n",
       "      <td>China News Service Premier Li Qiang attended t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txt_10.txt</td>\n",
       "      <td>At the invitation of Premier of the State Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txt_06.txt</td>\n",
       "      <td>The fourth LancangMekong Cooperation LMC Leade...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                                               Text\n",
       "0  txt_11.txt  We noted that General Secretary and President ...\n",
       "1  txt_05.txt  CCTV This year marks the tenth anniversary of ...\n",
       "2  txt_04.txt  China News Service Premier Li Qiang attended t...\n",
       "3  txt_10.txt  At the invitation of Premier of the State Coun...\n",
       "4  txt_06.txt  The fourth LancangMekong Cooperation LMC Leade..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra spaces from papers\n",
    "News_df['Text'] = News_df['Text'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "News_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f2dc3a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Spokesman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txt_01</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>29-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txt_02</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>28-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>txt_03</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>27-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txt_04</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>26-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txt_05</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>25-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Paper_ID                                              Title       Date  \\\n",
       "0   txt_01  Foreign Ministry Spokesperson Mao Nings Regula...  29-Dec-23   \n",
       "1   txt_02  Foreign Ministry Spokesperson Mao Nings Regula...  28-Dec-23   \n",
       "2   txt_03  Foreign Ministry Spokesperson Mao Nings Regula...  27-Dec-23   \n",
       "3   txt_04  Foreign Ministry Spokesperson Mao Nings Regula...  26-Dec-23   \n",
       "4   txt_05  Foreign Ministry Spokesperson Mao Nings Regula...  25-Dec-23   \n",
       "\n",
       "  Spokesman  \n",
       "0  Mao Ning  \n",
       "1  Mao Ning  \n",
       "2  Mao Ning  \n",
       "3  Mao Ning  \n",
       "4  Mao Ning  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata.\n",
    "metadata_df = pd.read_csv('metafile.csv')\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab513811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove .txt from title of each paper\n",
    "News_df['Filename'] = News_df['Filename'].str.replace('.txt', '', regex=True)\n",
    "\n",
    "# Rename column from paper ID to Title\n",
    "metadata_df.rename(columns={\"Paper_ID\": \"Filename\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fe17e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge metadata and papers into new DataFrame\n",
    "# Will only keep rows where both essay and metadata are present\n",
    "final_News_df = metadata_df.merge(News_df,on='Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ac6e295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Spokesman</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txt_01</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>29-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>CNR This year, President Xi Jinping visited As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txt_02</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>28-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>AFP Chinas Embassy in Myanmar today reminded a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>txt_03</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>27-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>CCTV This year marks the th anniversary of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txt_04</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>26-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>China News Service Premier Li Qiang attended t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txt_05</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>25-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>CCTV This year marks the tenth anniversary of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename                                              Title       Date  \\\n",
       "0   txt_01  Foreign Ministry Spokesperson Mao Nings Regula...  29-Dec-23   \n",
       "1   txt_02  Foreign Ministry Spokesperson Mao Nings Regula...  28-Dec-23   \n",
       "2   txt_03  Foreign Ministry Spokesperson Mao Nings Regula...  27-Dec-23   \n",
       "3   txt_04  Foreign Ministry Spokesperson Mao Nings Regula...  26-Dec-23   \n",
       "4   txt_05  Foreign Ministry Spokesperson Mao Nings Regula...  25-Dec-23   \n",
       "\n",
       "  Spokesman                                               Text  \n",
       "0  Mao Ning  CNR This year, President Xi Jinping visited As...  \n",
       "1  Mao Ning  AFP Chinas Embassy in Myanmar today reminded a...  \n",
       "2  Mao Ning  CCTV This year marks the th anniversary of the...  \n",
       "3  Mao Ning  China News Service Premier Li Qiang attended t...  \n",
       "4  Mao Ning  CCTV This year marks the tenth anniversary of ...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print DataFrame\n",
    "final_News_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fdfb9e",
   "metadata": {},
   "source": [
    "# Text Enrichment with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c36ea",
   "metadata": {},
   "source": [
    "## Creating Doc Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5e9f6e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Load nlp pipeline\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Check what functions it performs\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59b496ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that runs the nlp pipeline on any given input text\n",
    "def process_text(text):\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "608a7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the \"Text\" column, so that the nlp pipeline is called on each student essay\n",
    "final_News_df['Doc'] = final_News_df['Text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bf97c",
   "metadata": {},
   "source": [
    "# Text Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db51e32",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65590bb",
   "metadata": {},
   "source": [
    "A critical first step spaCy performs is tokenization, or the segmentation of strings into individual words and punctuation markers. Tokenization enables spaCy to parse the grammatical structures of a text and identify characteristics of each word-like part-of-speech.\n",
    "\n",
    "To retrieve a tokenized version of each text in the DataFrame, we’ll write a function that iterates through any given Doc object and returns all functions found within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "381d5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve tokens from a doc object\n",
    "def get_token(doc):\n",
    "    return [(token.text) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2549ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Spokesman</th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txt_01</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>29-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>CNR This year, President Xi Jinping visited As...</td>\n",
       "      <td>(CNR, This, year, ,, President, Xi, Jinping, v...</td>\n",
       "      <td>[CNR, This, year, ,, President, Xi, Jinping, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txt_02</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>28-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>AFP Chinas Embassy in Myanmar today reminded a...</td>\n",
       "      <td>(AFP, Chinas, Embassy, in, Myanmar, today, rem...</td>\n",
       "      <td>[AFP, Chinas, Embassy, in, Myanmar, today, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>txt_03</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>27-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>CCTV This year marks the th anniversary of the...</td>\n",
       "      <td>(CCTV, This, year, marks, the, th, anniversary...</td>\n",
       "      <td>[CCTV, This, year, marks, the, th, anniversary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txt_04</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>26-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>China News Service Premier Li Qiang attended t...</td>\n",
       "      <td>(China, News, Service, Premier, Li, Qiang, att...</td>\n",
       "      <td>[China, News, Service, Premier, Li, Qiang, att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txt_05</td>\n",
       "      <td>Foreign Ministry Spokesperson Mao Nings Regula...</td>\n",
       "      <td>25-Dec-23</td>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>CCTV This year marks the tenth anniversary of ...</td>\n",
       "      <td>(CCTV, This, year, marks, the, tenth, annivers...</td>\n",
       "      <td>[CCTV, This, year, marks, the, tenth, annivers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename                                              Title       Date  \\\n",
       "0   txt_01  Foreign Ministry Spokesperson Mao Nings Regula...  29-Dec-23   \n",
       "1   txt_02  Foreign Ministry Spokesperson Mao Nings Regula...  28-Dec-23   \n",
       "2   txt_03  Foreign Ministry Spokesperson Mao Nings Regula...  27-Dec-23   \n",
       "3   txt_04  Foreign Ministry Spokesperson Mao Nings Regula...  26-Dec-23   \n",
       "4   txt_05  Foreign Ministry Spokesperson Mao Nings Regula...  25-Dec-23   \n",
       "\n",
       "  Spokesman                                               Text  \\\n",
       "0  Mao Ning  CNR This year, President Xi Jinping visited As...   \n",
       "1  Mao Ning  AFP Chinas Embassy in Myanmar today reminded a...   \n",
       "2  Mao Ning  CCTV This year marks the th anniversary of the...   \n",
       "3  Mao Ning  China News Service Premier Li Qiang attended t...   \n",
       "4  Mao Ning  CCTV This year marks the tenth anniversary of ...   \n",
       "\n",
       "                                                 Doc  \\\n",
       "0  (CNR, This, year, ,, President, Xi, Jinping, v...   \n",
       "1  (AFP, Chinas, Embassy, in, Myanmar, today, rem...   \n",
       "2  (CCTV, This, year, marks, the, th, anniversary...   \n",
       "3  (China, News, Service, Premier, Li, Qiang, att...   \n",
       "4  (CCTV, This, year, marks, the, tenth, annivers...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [CNR, This, year, ,, President, Xi, Jinping, v...  \n",
       "1  [AFP, Chinas, Embassy, in, Myanmar, today, rem...  \n",
       "2  [CCTV, This, year, marks, the, th, anniversary...  \n",
       "3  [China, News, Service, Premier, Li, Qiang, att...  \n",
       "4  [CCTV, This, year, marks, the, tenth, annivers...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the token retrieval function on the doc objects in the dataframe\n",
    "final_News_df['Tokens'] = final_News_df['Doc'].apply(get_token)\n",
    "final_News_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e80c31b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNR This year, President Xi Jinping visited As...</td>\n",
       "      <td>[CNR, This, year, ,, President, Xi, Jinping, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFP Chinas Embassy in Myanmar today reminded a...</td>\n",
       "      <td>[AFP, Chinas, Embassy, in, Myanmar, today, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCTV This year marks the th anniversary of the...</td>\n",
       "      <td>[CCTV, This, year, marks, the, th, anniversary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China News Service Premier Li Qiang attended t...</td>\n",
       "      <td>[China, News, Service, Premier, Li, Qiang, att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCTV This year marks the tenth anniversary of ...</td>\n",
       "      <td>[CCTV, This, year, marks, the, tenth, annivers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  CNR This year, President Xi Jinping visited As...   \n",
       "1  AFP Chinas Embassy in Myanmar today reminded a...   \n",
       "2  CCTV This year marks the th anniversary of the...   \n",
       "3  China News Service Premier Li Qiang attended t...   \n",
       "4  CCTV This year marks the tenth anniversary of ...   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [CNR, This, year, ,, President, Xi, Jinping, v...  \n",
       "1  [AFP, Chinas, Embassy, in, Myanmar, today, rem...  \n",
       "2  [CCTV, This, year, marks, the, th, anniversary...  \n",
       "3  [China, News, Service, Premier, Li, Qiang, att...  \n",
       "4  [CCTV, This, year, marks, the, tenth, annivers...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = final_News_df[['Text', 'Tokens']].copy()\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0dc9e",
   "metadata": {},
   "source": [
    "# ❗️❗️Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0d692",
   "metadata": {},
   "source": [
    "# What are the most frequent words used in the speech?Does this express China's stance on international affairs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52e1dcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('china', 629), ('cooperation', 280), ('countries', 278), ('chinas', 241), ('two', 172), ('international', 167), ('president', 162), ('development', 161), ('us', 155), ('chinese', 153)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/josiechen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# Download NLTK stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Assuming 'Tokens' column contains a list of tokens for each document\n",
    "all_tokens = [token for tokens_list in final_News_df['Tokens'] for token in tokens_list]\n",
    "\n",
    "# Remove stop words and punctuation\n",
    "filtered_tokens = [token.lower() for token in all_tokens if token.lower() not in stop_words and token not in string.punctuation]\n",
    "\n",
    "# Analyze word frequency\n",
    "word_frequency = Counter(filtered_tokens)\n",
    "\n",
    "# Get the top N words\n",
    "N = 10  # Replace with the desired number of top words\n",
    "top_words = word_frequency.most_common(N)\n",
    "\n",
    "# Display the top words\n",
    "print(top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727c856",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35ac44",
   "metadata": {},
   "source": [
    "We can see that besides 'China,' the most frequently mentioned terms are 'cooperation' and 'development.' This indicates China's desire for friendly relations with other countries, the elimination of prejudice and discrimination, while also emphasizing its own stance and safeguarding the interests of the Chinese people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045a501",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861a89f",
   "metadata": {},
   "source": [
    "Another process performed by spaCy is lemmatization, or the retrieval of the dictionary root word of each word (for example “brighten” for “brightening”). We’ll perform a similar set of steps to those above to create a function to call the lemmas from the Doc object, then apply it to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "06f692c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve lemmas from a doc object\n",
    "def get_lemma(doc):\n",
    "    return [(token.lemma_) for token in doc]\n",
    "\n",
    "# Run the lemma retrieval function on the doc objects in the dataframe\n",
    "final_News_df['Lemmas'] = final_News_df['Doc'].apply(get_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0d195",
   "metadata": {},
   "source": [
    "# ❗️❗️Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36290512",
   "metadata": {},
   "source": [
    "# In the December press release, what topics did China mainly design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "70127e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('China', 629), ('country', 300), ('cooperation', 252), ('Chinas', 241), ('President', 159), ('chinese', 147), ('development', 147), ('international', 145), ('US', 138), ('year', 124)]\n",
      "Topic #1: ['china', 'right', 'human', 'chinas', 'philippines', 'country', 'president', 'mao', 'ning', 'issue']\n",
      "Topic #2: ['china', 'president', 'country', 'cooperation', 'year', 'chinese', 'international', 'chinas', 'new', 'development']\n",
      "Topic #3: ['china', 'cooperation', 'country', 'development', 'nam', 'president', 'relation', 'chinas', 'world', 'people']\n",
      "Topic #4: ['china', 'hong', 'law', 'chinas', 'kong', 'wang', 'issue', 'philippines', 'security', 'country']\n",
      "Topic #5: ['china', 'country', 'chinas', 'cooperation', 'international', 'foreign', 'development', 'chinese', 'wang', 'trade']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a function to process the text\n",
    "def process_text(text):\n",
    "    # Tokenize the text using spaCy\n",
    "    doc = nlp(text)\n",
    "    # Remove stop words and punctuation\n",
    "    tokens = [token.lemma_ for token in doc if token.lemma_ not in ENGLISH_STOP_WORDS and token.lemma_ not in string.punctuation]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Define a function to retrieve lemmas from a doc object\n",
    "def get_lemma(doc):\n",
    "    return [(token.lemma_) for token in doc]\n",
    "\n",
    "# Read your data into a DataFrame (assuming your data is in a variable named 'your_data')\n",
    "# final_News_df = pd.DataFrame(your_data)\n",
    "\n",
    "# Assuming you have a column named 'News' containing the text data\n",
    "# Apply text processing to the 'News' column\n",
    "final_News_df['Processed_Text'] = final_News_df['Text'].apply(process_text)\n",
    "\n",
    "# Run the token retrieval function on the doc objects in the dataframe\n",
    "final_News_df['Doc'] = final_News_df['Processed_Text'].apply(nlp)\n",
    "\n",
    "# Run the lemma retrieval function on the doc objects in the dataframe\n",
    "final_News_df['Lemmas'] = final_News_df['Doc'].apply(get_lemma)\n",
    "\n",
    "# Get all tokens\n",
    "all_tokens = [token for tokens_list in final_News_df['Lemmas'] for token in tokens_list]\n",
    "\n",
    "# Analyze word frequency\n",
    "word_frequency = Counter(all_tokens)\n",
    "\n",
    "# Get the top N words\n",
    "N = 10\n",
    "top_words = word_frequency.most_common(N)\n",
    "print(top_words)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(final_News_df['Processed_Text'])\n",
    "\n",
    "# Fit LDA model\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Display the topics and associated words\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic #{topic_idx + 1}:\", [vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-N - 1:-1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7633dafe",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f69330",
   "metadata": {},
   "source": [
    "These five themes cover several key aspects of China’s role on the international stage. \n",
    "\n",
    "-The first theme focuses on China’s human rights issues and its relationship with the Philippines. \n",
    "-The second theme involves China's domestic and international affairs, including the president, international cooperation and new developments. \n",
    "-The third theme emphasizes China's cooperation and development relations with other countries, involving Vietnam, presidential relations and international relations. \n",
    "-The fourth theme focuses on legal and security issues in China, including Hong Kong laws and Philippine issues. \n",
    "-Finally, the fifth theme involves China’s foreign relations, international cooperation and trade. \n",
    "\n",
    "The combination of these themes presents the diversity and importance of China in the global context, from human rights to international relations to law and security."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec9f3d",
   "metadata": {},
   "source": [
    "## Text Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf9d18",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9dbf4",
   "metadata": {},
   "source": [
    "spaCy facilitates two levels of part-of-speech tagging: coarse-grained tagging, which predicts the simple universal part-of-speech of each token in a text (such as noun, verb, adjective, adverb), and detailed tagging, which uses a larger, more fine-grained set of part-of-speech tags (for example 3rd person singular present verb). The part-of-speech tags used are determined by the English language model we use. In this case, we’re using the small English model, and you can explore the differences between the models on spaCy’s website.\n",
    "\n",
    "We can call the part-of-speech tags in the same way as the lemmas. Create a function to extract them from any given Doc object and apply the function to each Doc object in the DataFrame. The function we’ll create will extract both the coarse- and fine-grained part-of-speech for each token (token.pos_ and token.tag_, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88bed453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve lemmas from a doc object\n",
    "def get_pos(doc):\n",
    "    #Return the coarse- and fine-grained part of speech text for each token in the doc\n",
    "    return [(token.pos_, token.tag_) for token in doc]\n",
    "\n",
    "# Define a function to retrieve parts of speech from a doc object\n",
    "final_News_df['POS'] = final_News_df['Doc'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f40c9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract proper nouns from Doc object\n",
    "def extract_proper_nouns(doc):\n",
    "    return [token.text for token in doc if token.pos_ == 'PROPN']\n",
    "\n",
    "# Apply function to Doc column and store resulting proper nouns in new column\n",
    "final_News_df['Proper_Nouns'] = final_News_df['Doc'].apply(extract_proper_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7678c0",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baa7e2",
   "metadata": {},
   "source": [
    "spaCy can tag named entities in the text, such as names, dates, organizations, and locations. Call the full list of named entities and their descriptions using this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e408f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL : Numerals that do not fall under another type\n",
      "DATE : Absolute or relative dates or periods\n",
      "EVENT : Named hurricanes, battles, wars, sports events, etc.\n",
      "FAC : Buildings, airports, highways, bridges, etc.\n",
      "GPE : Countries, cities, states\n",
      "LANGUAGE : Any named language\n",
      "LAW : Named documents made into laws.\n",
      "LOC : Non-GPE locations, mountain ranges, bodies of water\n",
      "MONEY : Monetary values, including unit\n",
      "NORP : Nationalities or religious or political groups\n",
      "ORDINAL : \"first\", \"second\", etc.\n",
      "ORG : Companies, agencies, institutions, etc.\n",
      "PERCENT : Percentage, including \"%\"\n",
      "PERSON : People, including fictional\n",
      "PRODUCT : Objects, vehicles, foods, etc. (not services)\n",
      "QUANTITY : Measurements, as of weight or distance\n",
      "TIME : Times smaller than a day\n",
      "WORK_OF_ART : Titles of books, songs, etc.\n"
     ]
    }
   ],
   "source": [
    "# Get all NE labels and assign to variable\n",
    "labels = nlp.get_pipe(\"ner\").labels\n",
    "\n",
    "# Print each label and its description\n",
    "for label in labels:\n",
    "    print(label + ' : ' + spacy.explain(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5248738c",
   "metadata": {},
   "source": [
    "Let's check the named entity recognition of the full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4955e43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [ORG, PERSON, LOC, GPE, ORG, ORG, NORP, PERSON...\n",
       "1     [ORG, GPE, DATE, NORP, NORP, PERSON, PERSON, G...\n",
       "2     [ORG, FAC, PERSON, LOC, FAC, DATE, ORG, PERSON...\n",
       "3     [ORG, PERSON, ORG, DATE, PERSON, DATE, ORG, PE...\n",
       "4     [ORG, ORDINAL, PERSON, EVENT, GPE, PERSON, DAT...\n",
       "5     [ORDINAL, ORG, DATE, PERSON, PERSON, GPE, GPE,...\n",
       "6     [ORG, PERSON, GPE, GPE, GPE, PERSON, ORG, GPE,...\n",
       "7     [ORG, GPE, ORG, DATE, GPE, FAC, PERSON, ORG, F...\n",
       "8     [ORG, DATE, GPE, NORP, PERSON, ORG, PERSON, GP...\n",
       "9     [PERSON, PERSON, PERSON, GPE, DATE, NORP, NORP...\n",
       "10    [PERSON, GPE, PERSON, DATE, PERSON, GPE, PERSO...\n",
       "11    [ORG, ORG, ORG, ORG, ORG, GPE, DATE, ORG, GPE,...\n",
       "12    [GPE, PERSON, ORG, PERSON, PERSON, DATE, ORG, ...\n",
       "13    [ORG, DATE, GPE, PERSON, PERSON, ORG, PERSON, ...\n",
       "14    [ORG, DATE, GPE, ORG, ORG, ORG, GPE, PERSON, D...\n",
       "15    [GPE, DATE, NORP, NORP, DATE, NORP, ORG, PERSO...\n",
       "16    [GPE, PERSON, ORG, PERSON, PERSON, DATE, GPE, ...\n",
       "17    [GPE, ORG, PERSON, WORK_OF_ART, ORDINAL, DATE,...\n",
       "18    [ORG, DATE, ORG, ORG, GPE, GPE, GPE, ORG, PERS...\n",
       "19    [ORG, PERSON, PERSON, GPE, PERSON, GPE, DATE, ...\n",
       "20    [ORG, ORG, GPE, DATE, ORG, ORG, PERSON, ORG, O...\n",
       "Name: Named_Entities, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to extract named entities from doc objects\n",
    "def extract_named_entities(doc):\n",
    "    return [ent.label_ for ent in doc.ents]\n",
    "\n",
    "# Apply function to Doc column and store resulting named entities in new column\n",
    "final_News_df['Named_Entities'] = final_News_df['Doc'].apply(extract_named_entities)\n",
    "final_News_df['Named_Entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e1666",
   "metadata": {},
   "source": [
    "We can add another column with the words and phrases identified as named entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3da6919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [(CNR), (Xi, Jinping), (Asia, Africa, Europe, ...\n",
       "1     [(AFP, Chinas), (Myanmar), (today), (chinese),...\n",
       "2     [(CCTV), (Belt, Road, Initiative), (Xi, Jinpin...\n",
       "3     [(China, News, Service), (Li, Qiang), (Lancang...\n",
       "4     [(CCTV), (tenth), (Xi, Jinping), (Cold, War), ...\n",
       "5     [(fourth), (LancangMekong, Cooperation), (Dece...\n",
       "6     [(CCTV), (Steven, Barnett), (China), (China), ...\n",
       "7     [(Shenzhen, TV), (China), (Green, Silk, Road),...\n",
       "8     [(CCTV, Egypts, National, Elections, Authority...\n",
       "9     [(Li, Qiang), (Russian, Federation), (Mikhail,...\n",
       "10    [(Xi, Jinping), (Viet, Nam), (Mao), (December)...\n",
       "11    [(China, News, Service), (COP, Dubai), (Global...\n",
       "12    [(Rajoelina), (Xi, Jinpings), (National, Commi...\n",
       "13    [(CCTV), (December), (Argentinas), (Javier, Mi...\n",
       "14    [(CCTV), (December), (Philippines), (Renai, Ji...\n",
       "15    [(China), (January), (chinese), (chinese), (De...\n",
       "16    [(Argentina), (Xi, Jinpings), (Standing, Commi...\n",
       "17    [(Mekong), (Political, Bureau, CPC, Central, C...\n",
       "18    [(China, News, Service), (December), (Internat...\n",
       "19    [(Standing, Committee, Political, Bureau, CPC,...\n",
       "20    [(Reuters, Kyodo, News), (Beijing, Xiangshan, ...\n",
       "Name: NE_Words, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to extract text tagged with named entities from doc objects\n",
    "def extract_named_entities(doc):\n",
    "    return [ent for ent in doc.ents]\n",
    "\n",
    "# Apply function to Doc column and store resulting text in new column\n",
    "final_News_df['NE_Words'] = final_News_df['Doc'].apply(extract_named_entities)\n",
    "final_News_df['NE_Words']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bb338",
   "metadata": {},
   "source": [
    "Let’s visualize the words and their named entity tags in a single text. Call the first text’s Doc object and use displacy.render to visualize the text with the named entities highlighted and tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "378478ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AFP Chinas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Embassy \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Myanmar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    today\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " remind \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " national laukkae evacuate soon share information include possible mediation \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mao Ning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " current security situation \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kokang\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " selfadministere zone \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Myanmar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " severe complex like remind \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " national travel northern \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Myanmar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " national area especially \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Laukkaing Township\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " safety return \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " soon possible safety precaution \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " believe maintain momentum ceasefire peace talk serve relevant party \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Myanmar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " help ensure peace tranquility \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ChinaMyanmar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " border area \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " hope relevant party \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Myanmar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " exercise maximum restraint actively ease situation ground realize soft landing situation northern \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Myanmar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " concrete action protect safety security \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " project personnel \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Myanmar Shenzhen tv\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UKbased Financial Times\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " report early \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " impose lengthy approval process strict requirement impede project lay maintain undersea cable \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South China Sea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " force cable company reroute bypass \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " Sea Nikkei report owe lengthy approval \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " competent authority progress cable project \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South China Sea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " slow s comment \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mao Ning Undersea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " cable critical infrastructure global datum flow carry percent world intercontinental communication traffic important type information carrier international communication year \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " enhance international exchange cooperation cyberspace actively advance construction undersea cable type global information infrastructure \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " implement \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    United Nations\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Convention Law Sea letter spirit issue \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sea Areas Administration Law Marine Environment Protection Law Provisions\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " govern Laying Submarine Cables Pipelines Provisions govern Protection Submarine Cables Pipelines relevant law regulation identify country right obligation lay cable water \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " jurisdiction accordance law provide sound legal safeguard international undersea cable travel water \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " jurisdiction \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " welcome support country telecommunication company lay international undersea cable water \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " jurisdiction encourage collaboration \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " company foreign counterpart \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " continue work international community strengthen bilateral regional international dialogue cooperation actively advance building global information infrastructure include undersea cable jointly protect cable boost global digital connectivity jointly build fair equitable secure stable vibrant cyberspace community share future cyberspace</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the first Doc object\n",
    "doc = final_News_df['Doc'][1]\n",
    "\n",
    "# Visualize named entity tagging in a single paper\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dda258",
   "metadata": {},
   "source": [
    "# Download Enriched Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b157d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame as csv (in Google Drive)\n",
    "# Use this step only to save  csv to your computer's working directory\n",
    "final_News_df.to_csv('MICUSP_papers_with_spaCy_tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb2610d",
   "metadata": {},
   "source": [
    "# Analysis of Linguistic Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7527d0",
   "metadata": {},
   "source": [
    "## Part of Speech Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41dee4",
   "metadata": {},
   "source": [
    "spaCy counts the number of each part-of-speech tag that appears in each document (for example the number of times the NOUN tag appears in a document). This is called using doc.count_by(spacy.attrs.POS). Here’s how it works on a single sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1c547fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{95: 1, 87: 1, 97: 3, 90: 1, 92: 2}\n"
     ]
    }
   ],
   "source": [
    "# Create doc object from single sentence\n",
    "doc = nlp(\"This is 'an' example? sentence\")\n",
    "\n",
    "# Print counts of each part of speech in sentence\n",
    "print(doc.count_by(spacy.attrs.POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bea2d24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUX': 1, 'DET': 1, 'NOUN': 2, 'PRON': 1, 'PUNCT': 3}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store dictionary with indexes and POS counts in a variable\n",
    "num_pos = doc.count_by(spacy.attrs.POS)\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "# Create a new dictionary which replaces the index of each part of speech for its label (NOUN, VERB, ADJECTIVE)\n",
    "for k,v in sorted(num_pos.items()):\n",
    "  dictionary[doc.vocab[k].text] = v\n",
    "\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c25a2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame for analysis purposes\n",
    "pos_analysis_df = final_News_df[['Filename','Spokesman', 'Doc']]\n",
    "\n",
    "# Create list to store each dictionary\n",
    "num_list = []\n",
    "\n",
    "# Define a function to get part of speech tags and counts and append them to a new dictionary\n",
    "def get_pos_tags(doc):\n",
    "    dictionary = {}\n",
    "    num_pos = doc.count_by(spacy.attrs.POS)\n",
    "    for k,v in sorted(num_pos.items()):\n",
    "        dictionary[doc.vocab[k].text] = v\n",
    "    num_list.append(dictionary)\n",
    "\n",
    "# Apply function to each doc object in DataFrame\n",
    "pos_analysis_df.loc['C_POS'] = pos_analysis_df['Doc'].apply(get_pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98479122",
   "metadata": {},
   "source": [
    "# ❗️❗️Research question:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5497920e",
   "metadata": {},
   "source": [
    "## Do spokespersons Mao Ning and Wang Wenbing use certain parts of speech more frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "62f09b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spokesman</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>253</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>528</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>381</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>165</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>197</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>531</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>119</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>191</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>390</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>168</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>482</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>224</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>475</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>213</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>661</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>309</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>252</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>616</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>205</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>229</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>585</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spokesman  ADJ  ADP  ADV  AUX  DET  NOUN  PART  PRON  PROPN  PUNCT  \\\n",
       "0      Mao Ning  253  3.0   41  3.0  1.0   528   3.0  10.0    381    2.0   \n",
       "1      Mao Ning   52  1.0    8  NaN  NaN   118   1.0   NaN     71    NaN   \n",
       "2      Mao Ning   71  1.0    8  NaN  NaN   182   2.0   1.0    116    NaN   \n",
       "3      Mao Ning  165  3.0   37  2.0  NaN   407   1.0   NaN    338    NaN   \n",
       "4      Mao Ning  149  2.0   34  2.0  NaN   406   1.0   NaN    210    NaN   \n",
       "5   Wang Wenbin  197  3.0   30  3.0  NaN   531   3.0   1.0    365    NaN   \n",
       "6   Wang Wenbin  119  2.0   23  5.0  NaN   267   2.0   4.0    166    NaN   \n",
       "7   Wang Wenbin  191  2.0   23  4.0  NaN   507   1.0   6.0    509    NaN   \n",
       "8   Wang Wenbin  183  1.0   27  2.0  NaN   390   3.0   5.0    270    NaN   \n",
       "9   Wang Wenbin  168  4.0   36  2.0  NaN   482   5.0   1.0    389    NaN   \n",
       "10     Mao Ning  224  5.0   19  1.0  3.0   475   4.0   4.0    348    NaN   \n",
       "11     Mao Ning  106  NaN   21  NaN  NaN   284   3.0   NaN    255    NaN   \n",
       "12     Mao Ning  213  4.0   44  4.0  1.0   540   2.0   3.0    415    NaN   \n",
       "13     Mao Ning   68  NaN   14  1.0  NaN   168   NaN   NaN    166    NaN   \n",
       "14     Mao Ning  333  3.0   59  3.0  NaN   661   6.0   5.0    521    NaN   \n",
       "15  Wang Wenbin  309  2.0   66  5.0  NaN   767   1.0   7.0    528    NaN   \n",
       "16  Wang Wenbin  252  3.0   41  5.0  NaN   616   2.0   3.0    407    NaN   \n",
       "17  Wang Wenbin  205  4.0   28  3.0  NaN   502   1.0   4.0    411    1.0   \n",
       "18  Wang Wenbin   68  1.0   18  1.0  NaN   199   NaN   2.0    146    NaN   \n",
       "19  Wang Wenbin  229  7.0   46  4.0  1.0   585   2.0   4.0    573    NaN   \n",
       "20  Wang Wenbin  107  1.0   14  1.0  NaN   304   1.0   1.0    221    NaN   \n",
       "\n",
       "    SCONJ  VERB    X  NUM  INTJ  SYM  CCONJ  \n",
       "0     1.0   181  1.0  NaN   NaN  NaN    NaN  \n",
       "1     NaN    40  NaN  NaN   NaN  NaN    NaN  \n",
       "2     NaN    49  3.0  5.0   NaN  NaN    NaN  \n",
       "3     2.0   160  2.0  1.0   NaN  NaN    NaN  \n",
       "4     1.0   128  1.0  5.0   1.0  NaN    NaN  \n",
       "5     NaN   170  NaN  1.0   NaN  NaN    NaN  \n",
       "6     NaN    94  1.0  NaN   NaN  NaN    NaN  \n",
       "7     NaN   169  3.0  2.0   2.0  1.0    NaN  \n",
       "8     1.0   144  NaN  NaN   NaN  NaN    NaN  \n",
       "9     NaN   157  5.0  1.0   NaN  NaN    NaN  \n",
       "10    NaN   151  NaN  1.0   NaN  NaN    NaN  \n",
       "11    NaN   112  2.0  NaN   NaN  NaN    1.0  \n",
       "12    NaN   178  NaN  NaN   NaN  NaN    NaN  \n",
       "13    NaN    68  NaN  1.0   NaN  NaN    NaN  \n",
       "14    2.0   226  1.0  1.0   2.0  NaN    NaN  \n",
       "15    NaN   277  5.0  NaN   NaN  NaN    NaN  \n",
       "16    NaN   186  5.0  2.0   1.0  NaN    NaN  \n",
       "17    1.0   146  5.0  7.0   NaN  NaN    NaN  \n",
       "18    NaN    69  NaN  NaN   NaN  NaN    NaN  \n",
       "19    NaN   205  6.0  3.0   1.0  NaN    1.0  \n",
       "20    NaN    97  1.0  5.0   NaN  NaN    NaN  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe with part of speech counts\n",
    "pos_counts = pd.DataFrame(num_list)\n",
    "columns = list(pos_counts.columns)\n",
    "\n",
    "# Add discipline of each paper as new column to dataframe\n",
    "idx = 0\n",
    "new_col = pos_analysis_df['Spokesman']\n",
    "pos_counts.insert(loc=idx, column='Spokesman', value=new_col)\n",
    "\n",
    "pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0bc5463d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spokesman</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mao Ning</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wang Wenbin</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Spokesman    ADJ  ADP   ADV  AUX  DET   NOUN  PART  PRON  PROPN  PUNCT  \\\n",
       "0     Mao Ning  163.0  3.0  28.0  2.0  2.0  377.0   3.0   5.0  282.0    2.0   \n",
       "1  Wang Wenbin  184.0  3.0  32.0  3.0  1.0  468.0   2.0   3.0  362.0    1.0   \n",
       "\n",
       "   SCONJ   VERB    X  NUM  INTJ  SYM  CCONJ  \n",
       "0    2.0  129.0  2.0  2.0   2.0  NaN    1.0  \n",
       "1    1.0  156.0  4.0  3.0   1.0  1.0    1.0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average part of speech counts used in papers of each discipline\n",
    "average_pos_df = pos_counts.groupby(['Spokesman']).mean()\n",
    "\n",
    "# Round calculations to the nearest whole number\n",
    "average_pos_df = average_pos_df.round(0)\n",
    "\n",
    "# Reset index to improve DataFrame readability\n",
    "average_pos_df = average_pos_df.reset_index()\n",
    "\n",
    "# Show dataframe\n",
    "average_pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b258c",
   "metadata": {},
   "source": [
    "In the speech statistics for December, Wang Wenbing surpasses Mao Ning in various metrics. Even with an equal number of speeches, it is evident that Wang Wenbing utilizes a more diverse range of vocabulary and covers a broader range of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "62bf82b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=ADJ<br>Spokesman=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "ADJ",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "ADJ",
         "offsetgroup": "ADJ",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Mao Ning",
          "Wang Wenbin"
         ],
         "xaxis": "x",
         "y": [
          163,
          184
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=VERB<br>Spokesman=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "VERB",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "VERB",
         "offsetgroup": "VERB",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Mao Ning",
          "Wang Wenbin"
         ],
         "xaxis": "x",
         "y": [
          129,
          156
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=NUM<br>Spokesman=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "NUM",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "NUM",
         "offsetgroup": "NUM",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Mao Ning",
          "Wang Wenbin"
         ],
         "xaxis": "x",
         "y": [
          2,
          3
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=ADV<br>Spokesman=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "ADV",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "ADV",
         "offsetgroup": "ADV",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Mao Ning",
          "Wang Wenbin"
         ],
         "xaxis": "x",
         "y": [
          28,
          32
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Average Part-of-Speech Use in Papers Written by Biology and English Students"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Spokesman"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"56cb2ee7-c88d-4e00-8c0b-2a4e2814680c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"56cb2ee7-c88d-4e00-8c0b-2a4e2814680c\")) {                    Plotly.newPlot(                        \"56cb2ee7-c88d-4e00-8c0b-2a4e2814680c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=ADJ<br>Spokesman=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"ADJ\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"ADJ\",\"offsetgroup\":\"ADJ\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Mao Ning\",\"Wang Wenbin\"],\"xaxis\":\"x\",\"y\":[163.0,184.0],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=VERB<br>Spokesman=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"VERB\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"VERB\",\"offsetgroup\":\"VERB\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Mao Ning\",\"Wang Wenbin\"],\"xaxis\":\"x\",\"y\":[129.0,156.0],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=NUM<br>Spokesman=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"NUM\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"NUM\",\"offsetgroup\":\"NUM\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Mao Ning\",\"Wang Wenbin\"],\"xaxis\":\"x\",\"y\":[2.0,3.0],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=ADV<br>Spokesman=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"ADV\",\"marker\":{\"color\":\"#ab63fa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"ADV\",\"offsetgroup\":\"ADV\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Mao Ning\",\"Wang Wenbin\"],\"xaxis\":\"x\",\"y\":[28.0,32.0],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Spokesman\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Average Part-of-Speech Use in Papers Written by Biology and English Students\"},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('56cb2ee7-c88d-4e00-8c0b-2a4e2814680c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plotly to plot proper noun use per genre\n",
    "fig = px.bar(average_pos_df, x=\"Spokesman\", y=[\"ADJ\", 'VERB', \"NUM\",\"ADV\"], title=\"Average Part-of-Speech Use in Papers Written by Biology and English Students\", barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781ae01",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92267945",
   "metadata": {},
   "source": [
    "According to data visualization, overall, there isn't a significant difference in the language preferences of the two spokespersons. Wang Wenbing, relatively speaking, tends to use more nouns and verbs. This contributes to more persuasive and robust speeches, which may be related to gender differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b468c2",
   "metadata": {},
   "source": [
    "# Analysis of GPE Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e17807",
   "metadata": {},
   "source": [
    "# ❗️❗️Research question:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39c2c4",
   "metadata": {},
   "source": [
    "## In the December press briefings of the Ministry of Foreign Affairs, which country or region was mentioned the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3fe46dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China: 25\n",
      "Russia: 2\n",
      "San Francisco: 2\n",
      "Johannesburg: 1\n",
      "Beijing: 2\n",
      "Hanoi: 1\n",
      "Saudi Arabia: 1\n",
      "Iran: 1\n",
      "Ukraine: 4\n",
      "Palestine: 1\n",
      "US: 2\n",
      "UK: 1\n",
      "Hong Kong: 2\n",
      "Myanmar: 15\n",
      "Philippines: 4\n",
      "Jiao: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josiechen/anaconda3/lib/python3.11/site-packages/spacy/displacy/__init__.py:213: UserWarning:\n",
      "\n",
      "[W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">China China Russia San Francisco China Johannesburg China Beijing China Hanoi China Saudi Arabia Iran Ukraine Palestine China US US San Francisco Ukraine China Ukraine Beijing China China China China China China China UK Hong Kong Hong Kong Russia China Ukraine Myanmar Myanmar Myanmar Myanmar China Myanmar Myanmar Myanmar China Philippines China Jiao Philippines Philippines Philippines China Myanmar Myanmar China Myanmar Myanmar Myanmar Myanmar Myanmar China China Myanmar China China </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace the index with the desired document's index\n",
    "doc_to_analyze = final_News_df['Doc'][0]  # Replace 0 with the desired index\n",
    "\n",
    "# Extract only GPE entities\n",
    "gpe_entities = [ent.text for ent in doc_to_analyze.ents if ent.label_ == 'GPE']\n",
    "\n",
    "# Count the frequency of each GPE entity\n",
    "gpe_entity_counts = {}\n",
    "for entity in gpe_entities:\n",
    "    gpe_entity_counts[entity] = gpe_entity_counts.get(entity, 0) + 1\n",
    "\n",
    "# Print the frequency of each GPE entity\n",
    "for entity, count in gpe_entity_counts.items():\n",
    "    print(f'{entity}: {count}')\n",
    "\n",
    "# Visualize named entities of type GPE\n",
    "gpe_doc = spacy.tokens.Doc(doc_to_analyze.vocab, words=gpe_entities)\n",
    "displacy.render(gpe_doc, style='ent', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1d72",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e639f",
   "metadata": {},
   "source": [
    "According to the statistics, it can be observed that several countries and regions were mentioned, with China and Myanmar being mentioned the most. This is related to the recent international situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b23c7",
   "metadata": {},
   "source": [
    "# In conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6404f7e",
   "metadata": {},
   "source": [
    "In summary, the analysis of speeches from the two spokespersons reveals a common emphasis on terms such as 'cooperation' and 'development,' reflecting China's commitment to fostering friendly relations, eliminating prejudice, and safeguarding its people's interests. Data visualization indicates that, overall, there isn't a significant difference in the language preferences of the two spokespersons, but Wang Wenbing tends to employ more nouns and verbs, contributing to more persuasive speeches, possibly influenced by gender differences.\n",
    "\n",
    "Furthermore, the statistical findings highlight the frequent mentions of China and Myanmar, suggesting a correlation with recent international developments. This comprehensive overview sheds light on the spokespersons' communication strategies and the geopolitical context influencing their discourse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
